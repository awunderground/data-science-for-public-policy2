[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Science for Public Policy Part II",
    "section": "",
    "text": "Welcome\nThis book is the notes for Advanced Data Science for Public Policy in the McCourt School of Public Policy at Georgetown University."
  },
  {
    "objectID": "index.html#acknowledgements-more-to-come",
    "href": "index.html#acknowledgements-more-to-come",
    "title": "Data Science for Public Policy Part II",
    "section": "Acknowledgements (More to come!)",
    "text": "Acknowledgements (More to come!)\nThis book has benefited from many great teachers, collaborators, and students. First, I want to thank Gabe Morrison for excellent reviews and proofreading. Second, I want to thank Alex Engler and Alena Stern for collaborating on Intro to Data Science for Public Policy during six semesters and eight classes."
  },
  {
    "objectID": "01_advanced-quarto.html#sec-review",
    "href": "01_advanced-quarto.html#sec-review",
    "title": "1  Advanced Quarto",
    "section": "1.1 Review",
    "text": "1.1 Review\n\n1.1.1 Motivation\nThere are many problems worth avoiding in an analysis:\n\nCopying-and-pasting, transposing, and manual repetition\nRunning code out-of-order\nMaintaining parallel documents like a script for analysis and a doc for narrative\nCode written for computers that is tough to parse by humans\n\nNot convinced? Maybe we just want to make cool stuff like websites, blogs, books, and slide decks.\nQuarto, a literate statistical programming framework for R, Python, and Julia helps us solve many of these problems. Quarto uses\n\nplain text files ending in .qmd that are similar to .R and .Rmd files\nlibrary(knitr)\npandoc1\n\nQuarto uses library(knitr) and pandoc to convert plain text .qmd documents into rich output documents like these class notes. The “Render” button appears in RStudio with a .qmd file is open in the editor window.\nClicking the “Render” button begins the process of rendering .qmd files.\n\n\n\n\n\n\n\n\n\nWhen the button is clicked, Quarto calls library(knitr) and renders .qmd (Quarto files) into .md (Markdown files), which Pandoc then converts into any specified output type. Quarto and library(knitr) don’t need to be explicitly loaded as the entire process is handled by clicking the “Render” button in RStudio.\n\n\n\n\n\n\n\n\n\nSource: Quarto website\nQuarto, library(knitr), and Pandoc are all installed with RStudio. You will need to install a LaTeX distribution to render PDFs. We recommend library(tinytex) as a LaTeX distribution (installation instructions).\n\n\n\n\n\n\nExercise 1\n\n\n\n\nClick the new script button in RStudio and add a “Quarto Document”.\nGive the document a name, an author, and ensure that HTML is selected.\nSave the document as “hello-quarto.qmd”.\nClick “Render”.\n\n\n\nQuarto has three main ingredients:\n\nYAML header\nMarkdown text\nCode chunks\n\n\n\n1.1.2 (1) YAML Header\nYAML stands for “yet another markup language”. The YAML header contains meta information about the document including output type, document settings, and parameters that can be passed to the document. The YAML header starts with --- and ends with ---.\nHere is the simplest YAML header for a PDF document:\n---\nformat: pdf\n---\nYAML headers can contain many output specific settings. This YAML header creates an HTML document with code folding and a floating table of contents:\n---\nformat: \n  html:\n    embed-resources: true\n    code-fold: true\n    toc: true\n---  \nParameters can be specified as follows\n---\nformat: pdf\nparams:\n  state: \"Virginia\"\n---\nNow state can be referred to anywhere in R code as params$state. Parameters are useful for a couple of reasons:\n\nWe can clearly change key values for a Quarto document in the YAML header.\nWe can create a template and programmatically iterate the template over a set of values with the quarto_render() function and library(purrr). This blog outlines the idea. The Mobility Metrics Data Tables and SLFI State Fiscal Briefs are key examples of this workflow.\n\n\n\n\n\n\n\nWarning\n\n\n\nUnlike R Markdown, images and other content are not embedded in .html from Quarto by default. Be sure to include embed-resources: true in YAML headers to embed content and make documents easier to share.\nSuppose we embed an image called image.png in a Quarto document called example.qmd, which, when rendered, creates example.html. If we don’t include embed-resources: true, then we will need to share image.png and example.html to see the embedded image. This is also true for other files like .css.\n\n\n\n\n1.1.3 (2) Markdown text\nMarkdown is a shortcut for HyperText Markup Language (HTML). Essentially, simple meta characters corresponding to formatting are added to plain text.\nTitles and subtitltes\n------------------------------------------------------------\n\n# Title 1\n\n## Title 2\n\n### Title 3\n\n\nText formatting \n------------------------------------------------------------\n\n*italic*  \n\n**bold**   \n\n`code`\n\nLists\n------------------------------------------------------------\n\n* Bulleted list item 1\n* Item 2\n  * Item 2a\n  * Item 2b\n\n1. Item 1\n2. Item 2\n\nLinks and images\n------------------------------------------------------------\n\n[text](http://link.com)\n\n![Penguins](images/penguins.png)\n\n\n1.1.4 (3) Code chunks\n\n\n\n\n\nMore frequently, code is added in code chunks:\n\n```{r}\n2 + 2\n```\n\n[1] 4\n\n\nThe first argument inline or in a code chunk is the language engine. Most commonly, this will just be a lower case r. knitr allows for many different language engines:\n\nR\nJulia\nPython\nSQL\nBash\nRcpp\nStan\nJavascript\nCSS\n\nQuarto has a rich set of options that go inside of the chunks and control the behavior of Quarto.\n\n```{r}\n#| label: important-calculation\n#| eval: false\n\n2 + 2\n```\n\nIn this case, eval makes the code not run. Other chunk-specific settings can be added inside the brackets. Here2 are the most important options:\n\n\n\nOption\nEffect\n\n\n\n\necho: false\nHides code in output\n\n\neval: false\nTurns off evaluation\n\n\noutput: false\nHides code output\n\n\nwarning: false\nTurns off warnings\n\n\nmessage: false\nTurns off messages\n\n\nfig-height: 8\nChanges figure width in inches3\n\n\nfig-width: 8\nChanges figure height in inches4\n\n\n\nYou can see the quarto defaults for figure dimensions by format here.\nDefault settings for the entire document can be changed in the YAML header with the execute option:\nexecute:\n  warning: false\n\n\n\n\n\n\nExercise 2\n\n\n\n\nAdd date: today to your YAML header after title. This will update every time the document is rendered.\nCopy the Markdown table from this table generator and add it to your .qmd document.\nCreate a scatter plot of the cars data with library(ggplot2). Adjust the figure width and height using options within the chunk.\nClick “Render”.\n\n\n\n\n\n1.1.5 Organizing a Quarto Document\nIt is important to clearly organize a Quarto document and the constellation of files that typically support an analysis.\n\nAlways use .Rproj files.\nUse sub-directories to sort images, .css, data.\n\nLater, we will learn how to use library(here) to effectively organize sub-directories."
  },
  {
    "objectID": "01_advanced-quarto.html#math-notation",
    "href": "01_advanced-quarto.html#math-notation",
    "title": "1  Advanced Quarto",
    "section": "1.2 Math Notation",
    "text": "1.2 Math Notation\nThis course uses probability and statistics. Occasionally, we want to easily communicate with mathematical notation. For example, it may be convenient to type that \\(X\\) is a random variable that follows a standard normal distribution (mean = 0 and standard deviation = 1).\n\\[X \\sim N(\\mu = 0, \\sigma = 1)\\]\n\n1.2.1 Math Mode\nUse $ to start and stop in-line math notation and $$ to start multi-line math notation. Math notation uses LaTeX’s syntax for mathematical notation.\nHere’s an example with in-line math:\nConsider a binomially distributed random variable, $X \\sim binom(n, p)$. \nConsider a binomially distributed random variable, \\(X \\sim binom(n, p)\\).\nHere’s an example with a chunk of math:\n$$\nP(X = x) = {n \\choose x} p ^ x (1 - p) ^ {n - x}\n$${#eq-binomial}\n\\[\nP(X = x) = {n \\choose x} p ^ x (1 - p) ^ {n - x}\n\\tag{1.1}\\]\n\n\n1.2.2 Important Syntax\nMath mode recognizes basic math symbols available on your keyboard including +, -, *, /, &gt;, &lt;, (, and ).\nMath mode contains all greek letters. For example, \\alpha (\\(\\alpha\\)) and \\beta (\\(\\beta\\)).\n\n\nTable 1.1: My Caption\n\n\nLaTeX\nSymbol\n\n\n\n\n\\alpha\n\\(\\alpha\\)\n\n\n\\beta\n\\(\\beta\\)\n\n\n\\gamma\n\\(\\gamma\\)\n\n\n\\Delta\n\\(\\Delta\\)\n\n\n\\epsilon\n\\(\\epsilon\\)\n\n\n\\theta\n\\(\\theta\\)\n\n\n\\pi\n\\(\\pi\\)\n\n\n\\sigma\n\\(\\sigma\\)\n\n\n\\chi\n\\(\\chi\\)\n\n\n\n\nMath mode also recognizes \\(\\log(x)\\) (\\log(x)) and \\(\\sqrt{x}\\) (\\sqrt{x}).\nSuperscripts (^) are important for exponentiation and subscripts (_) are important for adding indices. y = x ^ 2 renders as \\(y = x ^ 2\\) and x_1, x_2, x_3 renders as \\(x_1, x_2, x_3\\). Brackets are useful for multi-character superscripts and subscripts like \\(s_{11}\\) (s_{11}).\nIt is useful to add symbols to letters. For example, \\bar{x} is useful for sample means (\\(\\bar{x}\\)), \\hat{y} is useful for predicted values (\\(\\hat{y}\\)), and \\vec{\\beta} is useful for vectors of coefficients (\\(\\vec{\\beta}\\)).\nMath mode supports fractions with \\frac{x}{y} (\\(\\frac{x}{y}\\)), big parentheses with \\left(\\right) (\\(\\left(\\right)\\)), and brackets with \\left[\\right] (\\(\\left[\\right]\\)).\nMath mode has a symbol for summation. Let’s combine it with bars, fractions, subscripts, and superscipts to show sample mean \\bar{x} = \\frac{1}{n}\\sum_i^n x_i, which looks like \\(\\bar{x} = \\frac{1}{n}\\sum_i^n x_i\\).\n\\sim is how to add the tilde for distributed as. For example, X \\sim N(\\mu = 0, \\sigma = 1) shows the normal distribution \\(X \\sim N(\\mu = 0, \\sigma = 1)\\).\nMatrices are are a little bit more work in math mode. Consider the follow variance-covariance matrix:\n\\begin{bmatrix}\ns_{11}^2 & s_{12}\\\\\ns_{21} & s_{22}^2\n\\end{bmatrix}\n\\[\n\\begin{bmatrix}\ns_{11}^2 & s_{12}\\\\\ns_{21} & s_{22}^2\n\\end{bmatrix}\n\\]\nThis guide provides and exhaustive look at math options in Quarto.\n\n\n\n\n\n\nWarning\n\n\n\nMath mode is finicky! Small errors like mismatched parentheses or superscript and subscript errors will cause Quarto documents to fail to render. Write math carefully and render early and often.\n\n\n\n\n\n\n\n\nExercise 3\n\n\n\n\nUse math mode to type out the equation for root mean square error (RMSE).\nDo you divide by n or n - 1?"
  },
  {
    "objectID": "01_advanced-quarto.html#cross-references",
    "href": "01_advanced-quarto.html#cross-references",
    "title": "1  Advanced Quarto",
    "section": "1.3 Cross References",
    "text": "1.3 Cross References\nCross references are useful for organizing documents that include sections, figures, tables, and equations. Cross references create hyperlinks within documents that jump to the locations of these elements. Linking sections, figures, tables, or equations helps readers navigate the document.\nCross references also automatically number the referenced elements. This means that if there are two tables (ie. Table 1 and Table 2) and a table is added between the two tables, all of the table numbers and references to the tables will automatically update.\nCross references require two bits of code within a Quarto document:\n\nA label associated with the section, figure, table, or equation.\nA reference to the labelled section, figure, table, or equation.\n\nLabels are written in brackets or as arguments in code chunks, and begin with the the type object being linked. References begin with @ followed by the label of object being linked.\n\n1.3.1 Sections\nLinking sections helps readers navigate between sections. Use brackets to label sections after headers and always begin labels with sec-. Then you can reference that section with @sec-.\n## Review {sec-review}\n\nSee @sec-review if you are totally lost.\nThe cross references shows up like this: See Section 1.1 if you are totally lost.\nIt can be helpful to turn on section numbering with number-sections: true in the YAML header. Additionally, Markdown has a native method for linking between sections.\n\n\n\n\n\n\nExercise 4\n\n\n\n\nAdd a few section headers to your Quarto document.\nAdd a cross reference to one of the section headers.\n\n\n\n\n\n1.3.2 Figures\n\n\n\nFigure 1.1: Penguins\n\n\nWe can reference figures like Figure 1.1 with @fig-penguins.\n\n\n1.3.3 Tables\nWe can link to tables in our documents. For example, we can link to the greek table with @tbl-greek Table 1.1.\n\n\n1.3.4 Equations\nWe can link to equations in our documents. For example, we can link to the binomial distribution earlier with @eq-binomial Equation 1.1.\n\n\n\n\n\n\nExercise 5\n\n\n\n\nAdd a cross reference to your RMSE equation from earlier."
  },
  {
    "objectID": "01_advanced-quarto.html#citations",
    "href": "01_advanced-quarto.html#citations",
    "title": "1  Advanced Quarto",
    "section": "1.4 Citations",
    "text": "1.4 Citations\n\n1.4.1 Zotero\nZotero is a free and open-source software for organizing research and managing citations.\n\n\n\n\n\n\nDigital Object Identifier (DOI)\n\n\n\nDOIs are persistent identifiers that uniquely identify objects including many academic papers. For example, 10.1198/jcgs.2009.07098 identifies “A Layered Grammar of Graphics” by Hadley Wickham.\n\n\n\n\n\n\n\n\nExercise 6\n\n\n\n\nInstall Zotero.\nFind the DOI for “Tidy Data” by Hadley Wickham.\nClick the magic wand in Zotero and paste the DOI.\n\n\n\n\n\n\n\n\n\n\n\nReview the new entry in Zotero.\n\n\n\n\n\n1.4.2 Zotero Integration\nZotero has a powerful integration with Quarto. In practice, it’s one click to add a DOI to Zotero and then one click to add a citation to Quarto.\nRStudio automatically adds My Library from Zotero. Simply switch to the Visual Editor (top left in RStudio), click “Insert”, and click “Citation”. This will open a prompt to insert a citation into the Quarto document.\nThe citation is automatically added with parentheses to go at the end of sentences. Delete the square brackets to convert the citation to an in-line citation.\nInserting the citation automatically adds the citation to the references section. Deleting the reference automatically deletes the citation from the references section.\nZotero Groups are useful for sharing citations and Zotero Group Libraries need to be added to RStudio. To set this up:\nTo set this up, in RStudio:\n\nGo to Tools and select “Global Options”\nSelect “RMarkdown” and then click “Citations”\nFor “Use Libraries” choose “Selected Libraries”\nSelect the group libraries to add\n\n\n\n\n\n\n\nExercise 7\n\n\n\n\nCite “Tidy Data” by Hadley Wickham in your Quarto document.\nClick “Render”"
  },
  {
    "objectID": "01_advanced-quarto.html#more-resources",
    "href": "01_advanced-quarto.html#more-resources",
    "title": "1  Advanced Quarto",
    "section": "1.5 More Resources",
    "text": "1.5 More Resources\n\nQuarto Guide\nIterating fact sheets and web pages with Quarto"
  },
  {
    "objectID": "01_advanced-quarto.html#footnotes",
    "href": "01_advanced-quarto.html#footnotes",
    "title": "1  Advanced Quarto",
    "section": "",
    "text": "Pandoc is free software that converts documents between markup formats. For example, Pandoc can convert files to and from markdown, LaTeX, jupyter notebook (ipynb), and Microsoft Word (.docx) formats, among many others. You can see a comprehensive list of files Pandoc can convert on their About Page.↩︎\nThis table was typed as Markdown code. But sometimes it is easier to use a code chunk to create and print a table. Pipe any data frame into knitr::kable() to create a table that will be formatted in the output of a rendered Quarto document.↩︎\nThe default dimensions for figures change based on the output format. Visit here to learn more.↩︎\nThe default dimensions for figures change based on the output format. Visit here to learn more.↩︎"
  },
  {
    "objectID": "02_advanced-data-cleaning.html#sec-review2",
    "href": "02_advanced-data-cleaning.html#sec-review2",
    "title": "2  Advanced Data Cleaning",
    "section": "2.1 Review",
    "text": "2.1 Review\nR for Data Science (2e) displays the first steps of the data science process as “Import”, “Tidy”, and “Transform”. DSPP1 introduced important techniques for importing data like read_csv() and querying web APIs, for tidying data like pivot_longer(), and for transforming data like mutate().\n\n\n\n\n\n\nExercise 1\n\n\n\n\nUse mutate() and case_when() to a new variable to cars where the values are \"slow\" when speed &lt; 10, \"moderate\" when speed &lt; 20, and \"fast\" otherwise."
  },
  {
    "objectID": "02_advanced-data-cleaning.html#sec-import",
    "href": "02_advanced-data-cleaning.html#sec-import",
    "title": "2  Advanced Data Cleaning",
    "section": "2.2 Import",
    "text": "2.2 Import\n\n2.2.1 library(here)\nDeveloping Quarto documents in subdirectories is a pain. When interactively running code in the console, file paths are read as if the .qmd file is in the same folder as the .Rproj. When clicking render, paths are treated as if they are in the subdirectory where the .qmd file is.\nlibrary(here) resolves headaches around file referencing in project-oriented workflows.\nLoading library(here) will print your working directory.\n\nlibrary(here)\n\nhere() starts at /Users/aaronwilliams/presentations/data-science-for-public-policy2\n\n\nAfter this, here() will use reasonable heuristics to find project files using relative file paths. When placing Quarto documents in a directory below the top-level directory, use here() and treat each folder and file as a different string.\nBefore\n\nread_csv(\"data/raw/important-data.csv\")\n\nAfter\n\nread_csv(here(\"data\", \"raw\", \"important-data.csv\"))\n\n\n\n2.2.2 library(readxl)\nWe will focus on reading data from Excel workbooks. Excel is a bad tool with bad design that has led to many analytical errors. Unfortunately, it’s a dominant tool for storing data and often enters the data science workflow.\nlibrary(readxl) is the premier package for reading data from .xls and .xlsx files. read_excel(), which works like read_csv(), loads data from .xls and .xlsx files. Consider data from the Urban Institute’s Debt in America feature accessed through the Urban Institute Data Catalog.\n\nlibrary(readxl)\n\nread_excel(here(\"data\", \"state_dia_delinquency_ 7 Jun 2022.xlsx\"))\n\n# A tibble: 51 × 28\n   fips  state_name          state Share with Any Debt …¹ Share with Any Debt …²\n   &lt;chr&gt; &lt;chr&gt;               &lt;chr&gt; &lt;chr&gt;                  &lt;chr&gt;                 \n 1 01    Alabama             AL    .3372881               .5016544              \n 2 02    Alaska              AK    .1672429               .221573               \n 3 04    Arizona             AZ    .2666938               .3900013              \n 4 05    Arkansas            AR    .3465793               .5426918              \n 5 06    California          CA    .2087713               .2462195              \n 6 08    Colorado            CO    .213803                .3554938              \n 7 09    Connecticut         CT    .2194708               .3829038              \n 8 10    Delaware            DE    .2866829               .469117               \n 9 11    District of Columb… DC    .2232908               .3485817              \n10 12    Florida             FL    .2893825               .3439322              \n# ℹ 41 more rows\n# ℹ abbreviated names: ¹​`Share with Any Debt in Collections, All`,\n#   ²​`Share with Any Debt in Collections, Communities of Color`\n# ℹ 23 more variables:\n#   `Share with Any Debt in Collections, Majority White Communities` &lt;chr&gt;,\n#   `Median Debt in Collections, All` &lt;chr&gt;,\n#   `Median Debt in Collections, Communities of Color` &lt;chr&gt;, …\n\n\nread_excel() has several useful arguments:\n\nsheet selects the sheet to read.\nrange selects the cells to read and can use Excel-style ranges like “C34:D50”.\nskip skips the selected number of rows.\nn_max selects the maximum number of rows to read.\n\nExcel encourages bad habits and untidy data, so these arguments are useful for extracting data from messy Excel workbooks.\nreadxl_example() contains a perfect example. The workbook contains two sheets, which we can see with excel_sheets().\n\nreadxl_example(\"clippy.xlsx\") |&gt;\n  excel_sheets()\n\n[1] \"list-column\"    \"two-row-header\"\n\n\nAs is common with many Excel workbooks, the second sheet contains a second row of column names with parenthetical comments about each column.1\n\nreadxl_example(\"clippy.xlsx\") |&gt;  \n  read_excel(sheet = \"two-row-header\")\n\n# A tibble: 2 × 4\n  name       species              death                 weight    \n  &lt;chr&gt;      &lt;chr&gt;                &lt;chr&gt;                 &lt;chr&gt;     \n1 (at birth) (office supply type) (date is approximate) (in grams)\n2 Clippy     paperclip            39083                 0.9       \n\n\nThis vignette suggests a simple solution to this problem.\n\n# extract the column names\ncol_names &lt;- readxl_example(\"clippy.xlsx\") |&gt;  \n  read_excel(sheet = \"two-row-header\", n_max = 0) |&gt;\n  names()\n\n# load the data and add the column names\nreadxl_example(\"clippy.xlsx\") |&gt;  \n    read_excel(\n      sheet = \"two-row-header\", \n      skip = 2,\n      col_names = col_names\n    )\n\n# A tibble: 1 × 4\n  name   species   death               weight\n  &lt;chr&gt;  &lt;chr&gt;     &lt;dttm&gt;               &lt;dbl&gt;\n1 Clippy paperclip 2007-01-01 00:00:00    0.9\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\nThe IRS Statistics of Income Division is one of the US’s 13 principal statistical agencies. They publish rich information derived from tax returns. We will focus on Table 2, Adjusted Gross Income (AGI) percentiles by state.\n\nRead in the 52 cells in the first column that contain “United States”, all 50 states, and the “District of Columbia”.\nIdentify the cells containing data for “Adjusted gross income floor on percentiles”. Read in the data with read_excel(). Either programmatically read in the column names (i.e. “Top 1 Percent”, …) or assign them with col_names().\nUse bind_cols() to combine the data from step 1 and step 2.\n\n\n\nlibrary(tidyxl) contains tools for working with messy Excel workbooks, library(openxlsx) contains tools for creating Excel workbooks with R, and library(googlesheets4) contains tools for working with Google Sheets."
  },
  {
    "objectID": "02_advanced-data-cleaning.html#sec-tidy",
    "href": "02_advanced-data-cleaning.html#sec-tidy",
    "title": "2  Advanced Data Cleaning",
    "section": "2.3 Tidy",
    "text": "2.3 Tidy\nThe defining opinion of the tidyverse is its wholehearted adoption of tidy data. Tidy data has three features:\n\nEach variable forms a column.\nEach observation forms a row.\nEach type of observational unit forms a dataframe.\n\n\nTidy datasets are all alike, but every messy dataset is messy in its own way. ~ Hadley Wickham\n\nlibrary(tidyr) is the main package for tidying untidy data. We’ll practice some skills using examples from three workbooks from the IRS SOI.\npivot_longer() is commonly used for tidying data and for making data longer for library(ggplot2). pivot_longer() reorients data so that key-value pairs expressed as column name-column value are column value-column value in adjacent columns. pivot_longer() has three essential arguments:\n\ncols is a vector of columns to pivot (or not pivot).\nnames_to is a string for the name of the column where the old column names will go (i.e. “series” in the figure).\nvalues_to is a string for the name of the column where the values will go (i.e. “rate” in the figure).\n\n\n\n\n\n\npivot_wider() is the inverse of pivot_longer().\n\nTidying Example 1\n\nUntidyCleaned\n\n\nWhy aren’t the data tidy?\n\ntable1 &lt;- tribble(\n  ~state, ~agi2006, ~agi2016, ~agi2020,\n  \"Alabama\", 95067, 114510, 138244,\n  \"Alaska\", 17458, 23645, 26445,\n  \"Arizona\", 146307, 181691, 245258\n)\n\ntable1\n\n# A tibble: 3 × 4\n  state   agi2006 agi2016 agi2020\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 Alabama   95067  114510  138244\n2 Alaska    17458   23645   26445\n3 Arizona  146307  181691  245258\n\n\n\n\nYear is a variable. This data is untidy because year is included in the column names.\n\ntable1 &lt;- tribble(\n  ~state, ~agi2006, ~agi2016, ~agi2020,\n  \"Alabama\", 95067, 114510, 138244,\n  \"Alaska\", 17458, 23645, 26445,\n  \"Arizona\", 146307, 181691, 245258\n)\n\ntable1\n\n# A tibble: 3 × 4\n  state   agi2006 agi2016 agi2020\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 Alabama   95067  114510  138244\n2 Alaska    17458   23645   26445\n3 Arizona  146307  181691  245258\n\npivot_longer(\n  data = table1, \n  cols = -state, \n  names_to = \"year\", \n  values_to = \"agi\"\n)\n\n# A tibble: 9 × 3\n  state   year       agi\n  &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt;\n1 Alabama agi2006  95067\n2 Alabama agi2016 114510\n3 Alabama agi2020 138244\n4 Alaska  agi2006  17458\n5 Alaska  agi2016  23645\n6 Alaska  agi2020  26445\n7 Arizona agi2006 146307\n8 Arizona agi2016 181691\n9 Arizona agi2020 245258\n\n\nThe year column isn’t useful yet. We’ll fix that later.\n\n\n\n\nlibrary(tidyr) contains several functions to split values into multiple cells.\n\nseparate_wider_delim() separates a value based on a delimeter and creates wider data.\nseparate_wider_position() separates a value based on position and creates wider data.\nseparate_longer_delim() separates a value based on a delimeter and creates longer data.\nseparate_longer_position() separates a value based on position and creates longer data.\n\n\n\nTidying Example 2\n\nUntidyCleaned\n\n\nWhy aren’t the data tidy?\n\ntable2 &lt;- tribble(\n  ~state, ~`agi2006|2016|2020`,\n  \"Alabama\", \"95067|114510|138244\",\n  \"Alaska\", \"17458|23645|26445\",\n  \"Arizona\", \"146307|181691|245258\"\n)\n\ntable2\n\n# A tibble: 3 × 2\n  state   `agi2006|2016|2020` \n  &lt;chr&gt;   &lt;chr&gt;               \n1 Alabama 95067|114510|138244 \n2 Alaska  17458|23645|26445   \n3 Arizona 146307|181691|245258\n\n\n\n\nThe values for 2006, 2016, and 2020 are all squished into one cell.\n\ntable2 &lt;- tribble(\n  ~state, ~`agi2006|2016|2020`,\n  \"Alabama\", \"95067|114510|138244\",\n  \"Alaska\", \"17458|23645|26445\",\n  \"Arizona\", \"146307|181691|245258\"\n)\n\ntable2\n\n# A tibble: 3 × 2\n  state   `agi2006|2016|2020` \n  &lt;chr&gt;   &lt;chr&gt;               \n1 Alabama 95067|114510|138244 \n2 Alaska  17458|23645|26445   \n3 Arizona 146307|181691|245258\n\nseparate_wider_delim(\n  data = table2, \n  cols = `agi2006|2016|2020`, \n  delim = \"|\",\n  names = c(\"2006\", \"2016\", \"2020\")\n) |&gt;\n  pivot_longer(\n    cols = -state,\n    names_to = \"year\", \n    values_to = \"agi\"\n  )\n\n# A tibble: 9 × 3\n  state   year  agi   \n  &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; \n1 Alabama 2006  95067 \n2 Alabama 2016  114510\n3 Alabama 2020  138244\n4 Alaska  2006  17458 \n5 Alaska  2016  23645 \n6 Alaska  2020  26445 \n7 Arizona 2006  146307\n8 Arizona 2016  181691\n9 Arizona 2020  245258\n\n\n\n\n\n\nbind_rows() combines data frames by stacking the rows.\n\none &lt;- tribble(\n  ~id, ~var,\n  \"1\", 3.14,\n  \"2\", 3.15,\n)\n\ntwo &lt;- tribble(\n  ~id, ~var,\n  \"3\", 3.16,\n  \"4\", 3.17,\n)\n\nbind_rows(one, two)\n\n# A tibble: 4 × 2\n  id      var\n  &lt;chr&gt; &lt;dbl&gt;\n1 1      3.14\n2 2      3.15\n3 3      3.16\n4 4      3.17\n\n\nbind_cols() combines data frames by appending columns.\n\nthree &lt;- tribble(\n  ~id, ~var1,\n  \"1\", 3.14,\n  \"2\", 3.15,\n)\n\nfour &lt;- tribble(\n  ~id, ~var2,\n  \"1\", 3.16,\n  \"2\", 3.17,\n)\n\nbind_cols(three, four)\n\nNew names:\n• `id` -&gt; `id...1`\n• `id` -&gt; `id...3`\n\n\n# A tibble: 2 × 4\n  id...1  var1 id...3  var2\n  &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;\n1 1       3.14 1       3.16\n2 2       3.15 2       3.17\n\n\nWhen possible, we recommend using relational joins like left_join() to combine by columns because it is easy to miss-align rows with bind_cols().\n\nleft_join(\n  x = three,\n  y = four,\n  by = \"id\"\n)\n\n# A tibble: 2 × 3\n  id     var1  var2\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 1      3.14  3.16\n2 2      3.15  3.17\n\n\n\n\nTidying Example 3\n\nUntidyCleaned\n\n\nWhy aren’t the data tidy?\n\ntable3_2006 &lt;- tribble(\n  ~state, ~agi,\n  \"Alabama\", \"95067\",\n  \"Alaska\", \"17458\",\n  \"Arizona\", \"146307\"\n)\n\ntable3_2006\n\n# A tibble: 3 × 2\n  state   agi   \n  &lt;chr&gt;   &lt;chr&gt; \n1 Alabama 95067 \n2 Alaska  17458 \n3 Arizona 146307\n\ntable3_2016 &lt;- tribble(\n  ~state, ~agi,\n  \"Alabama\", \"114510\",\n  \"Alaska\", \"23645\",\n  \"Arizona\", \"181691\"\n)\n\ntable3_2016\n\n# A tibble: 3 × 2\n  state   agi   \n  &lt;chr&gt;   &lt;chr&gt; \n1 Alabama 114510\n2 Alaska  23645 \n3 Arizona 181691\n\ntable3_2020 &lt;- tribble(\n  ~state, ~`agi`,\n  \"Alabama\", \"138244\",\n  \"Alaska\", \"26445\",\n  \"Arizona\", \"245258\"\n)\n\ntable3_2020\n\n# A tibble: 3 × 2\n  state   agi   \n  &lt;chr&gt;   &lt;chr&gt; \n1 Alabama 138244\n2 Alaska  26445 \n3 Arizona 245258\n\n\n\n\nThe variable year is contained in the data set names. The .id argument in bind_rows() allows us to create the year variable.\n\ntable3_2006 &lt;- tribble(\n  ~state, ~agi,\n  \"Alabama\", 95067,\n  \"Alaska\", 17458,\n  \"Arizona\", 146307\n)\n\ntable3_2006\n\n# A tibble: 3 × 2\n  state      agi\n  &lt;chr&gt;    &lt;dbl&gt;\n1 Alabama  95067\n2 Alaska   17458\n3 Arizona 146307\n\ntable3_2016 &lt;- tribble(\n  ~state, ~agi,\n  \"Alabama\", 114510,\n  \"Alaska\", 23645,\n  \"Arizona\", 181691\n)\n\ntable3_2016\n\n# A tibble: 3 × 2\n  state      agi\n  &lt;chr&gt;    &lt;dbl&gt;\n1 Alabama 114510\n2 Alaska   23645\n3 Arizona 181691\n\ntable3_2020 &lt;- tribble(\n  ~state, ~`agi`,\n  \"Alabama\", 138244,\n  \"Alaska\", 26445,\n  \"Arizona\", 245258\n)\n\ntable3_2020\n\n# A tibble: 3 × 2\n  state      agi\n  &lt;chr&gt;    &lt;dbl&gt;\n1 Alabama 138244\n2 Alaska   26445\n3 Arizona 245258\n\nbind_rows(\n  `2006` = table3_2006,\n  `2016` = table3_2016,\n  `2020` = table3_2020,\n  .id = \"year\"\n)\n\n# A tibble: 9 × 3\n  year  state      agi\n  &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt;\n1 2006  Alabama  95067\n2 2006  Alaska   17458\n3 2006  Arizona 146307\n4 2016  Alabama 114510\n5 2016  Alaska   23645\n6 2016  Arizona 181691\n7 2020  Alabama 138244\n8 2020  Alaska   26445\n9 2020  Arizona 245258\n\n\n\n\n\n\nRelational joins are fundamental to working with tidy data. Tidy data can only contain one unit of observation (e.g. county or state not county and state). When data exist on multiple levels, they must be stored in separate tables that can later be combined.\n\n\n\n\n\n\nMutating Joins\n\n\n\nMutating joins add new variables to a data frame by matching observations from one data frame to observations in another data frame.\n\n\n\n\n\n\n\n\nFiltering Joins\n\n\n\nFiltering joins drop observations based on the presence of their key (identifier) in another data frame.\nFor example, we may have a list of students in detention and a list of all students. We can use a filtering join to create a list of student not in detention.\n\n\nFor now, we will focus on mutating joins. Let their be two data frames x and y and let both data frames have a key variable that uniquely identifies rows.\n\nleft_join(x, y) appends variables from y on to x but only keeps observations from x.\nfull_join(x, y) appends variables from y on to x and keeps all observations from x and y.\nanti_join(x, y) returns all observations from x without a match in y. anti_join() is traditionally only used for filtering joins, but it is useful for writing tests for mutating joins.\n\nTo learn more, read the Joins chapter of R for Data Science (2e). library(tidylog) is a useful function for monitoring the behavior of joins.\n\n\nTidying Example 4\n\nUntidyCleaned\n\n\nWhy aren’t the data tidy?\n\ntable4a &lt;- tribble(\n  ~state, ~agi,\n  \"Alabama\", 95067,\n  \"Alaska\", 17458,\n  \"Arizona\", 146307\n)\n\ntable4a\n\n# A tibble: 3 × 2\n  state      agi\n  &lt;chr&gt;    &lt;dbl&gt;\n1 Alabama  95067\n2 Alaska   17458\n3 Arizona 146307\n\ntable4b &lt;- tribble(\n  ~state, ~returns,\n  \"Alabama\", 1929941,\n  \"Alaska\", 322369,\n  \"Arizona\", 2454951\n)\n\ntable4b\n\n# A tibble: 3 × 2\n  state   returns\n  &lt;chr&gt;     &lt;dbl&gt;\n1 Alabama 1929941\n2 Alaska   322369\n3 Arizona 2454951\n\n\n\n\nThese data are tidy! But keeping the data in two separate data frames may not make sense. Let’s use full_join() to combine the data and anti_join() to see if there are mismatches.\n\ntable4a &lt;- tribble(\n  ~state, ~agi,\n  \"Alabama\", 95067,\n  \"Alaska\", 17458,\n  \"Arizona\", 146307\n)\n\ntable4a\n\n# A tibble: 3 × 2\n  state      agi\n  &lt;chr&gt;    &lt;dbl&gt;\n1 Alabama  95067\n2 Alaska   17458\n3 Arizona 146307\n\ntable4b &lt;- tribble(\n  ~state, ~returns,\n  \"Alabama\", 1929941,\n  \"Alaska\", 322369,\n  \"Arizona\", 2454951\n)\n\ntable4b\n\n# A tibble: 3 × 2\n  state   returns\n  &lt;chr&gt;     &lt;dbl&gt;\n1 Alabama 1929941\n2 Alaska   322369\n3 Arizona 2454951\n\nfull_join(table4a, table4b, by = \"state\")\n\n# A tibble: 3 × 3\n  state      agi returns\n  &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1 Alabama  95067 1929941\n2 Alaska   17458  322369\n3 Arizona 146307 2454951\n\nanti_join(table4a, table4b, by = \"state\")\n\n# A tibble: 0 × 2\n# ℹ 2 variables: state &lt;chr&gt;, agi &lt;dbl&gt;\n\nanti_join(table4b, table4a, by = \"state\")\n\n# A tibble: 0 × 2\n# ℹ 2 variables: state &lt;chr&gt;, returns &lt;dbl&gt;\n\n\n\n\n\n\n\n\n\n\n\nExercise 3\n\n\n\n\nUse pivot_longer() to make the SOI percentile data from the earlier exercise longer. After the transformation, there should be one row per percentile per state.\n\n\n\nTo see more examples, read the tidy data section in R for Data Science (2e)"
  },
  {
    "objectID": "02_advanced-data-cleaning.html#sec-transform",
    "href": "02_advanced-data-cleaning.html#sec-transform",
    "title": "2  Advanced Data Cleaning",
    "section": "2.4 Transform",
    "text": "2.4 Transform\n\n2.4.1 Strings\nCheck out the stringr cheat sheet.\nlibrary(stringr) contains powerful functions for working with strings in R. In data analysis, we may need to detect matches, subset strings, work with the lengths of strings, modify strings, and join and split strings.\n\nDetecting Matches\nstr_detect() is useful for detecting matches in strings, which can be useful with filter(). Consider the executive orders data set and suppose we want to return executive orders that contain the word \"Virginia\".\n\neos &lt;- read_csv(here(\"data\", \"executive-orders.csv\")) |&gt;\n  filter(!is.na(text)) |&gt;\n  group_by(executive_order_number) |&gt;\n  summarize(text = list(text)) |&gt;\n  mutate(text = map_chr(text, ~paste(.x, collapse = \" \")))\n\nRows: 196537 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): text, president\ndbl  (1): executive_order_number\ndate (1): signing_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\neos\n\n# A tibble: 1,126 × 2\n   executive_order_number text                                                  \n                    &lt;dbl&gt; &lt;chr&gt;                                                 \n 1                  12890 \"Executive Order 12890 of December 30, 1993 Amendment…\n 2                  12944 \"Executive Order 12944 of December 28, 1994 Adjustmen…\n 3                  12945 \"Executive Order 12945 of January 20, 1995 Amendment …\n 4                  12946 \"Executive Order 12946 of January 20, 1995 President'…\n 5                  12947 \"Executive Order 12947 of January 23, 1995 Prohibitin…\n 6                  12948 \"Executive Order 12948 of January 30, 1995 Amendment …\n 7                  12949 \"Executive Order 12949 of February 9, 1995 Foreign In…\n 8                  12950 \"Executive Order 12950 of February 22, 1995 Establish…\n 9                  12951 \"Executive Order 12951 of February 22, 1995 Release o…\n10                  12952 \"Executive Order 12952 of February 24, 1995 Amendment…\n# ℹ 1,116 more rows\n\neos |&gt;\n  filter(str_detect(string = text, pattern = \"Virginia\"))\n\n# A tibble: 6 × 2\n  executive_order_number text                                                   \n                   &lt;dbl&gt; &lt;chr&gt;                                                  \n1                  13150 Executive Order 13150 of April 21, 2000 Federal Workfo…\n2                  13508 Executive Order 13508 of May 12, 2009 Chesapeake Bay P…\n3                  13557 Executive Order 13557 of November 4, 2010 Providing an…\n4                  13775 Executive Order 13775 of February 9, 2017 Providing an…\n5                  13787 Executive Order 13787 of March 31, 2017 Providing an O…\n6                  13934 Executive Order 13934 of July 3, 2020 Building and Reb…\n\n\n\n\nSubsetting Strings\nstr_sub() can subset strings based on positions within the string. Consider an example where we want to extract state FIPS codes from county FIPS codes.\n\ntibble(fips = c(\"01001\", \"02013\", \"04001\")) |&gt;\n  mutate(state_fips = str_sub(fips, start = 1, end = 2))\n\n# A tibble: 3 × 2\n  fips  state_fips\n  &lt;chr&gt; &lt;chr&gt;     \n1 01001 01        \n2 02013 02        \n3 04001 04        \n\n\n\n\nManaging Lengths\nstr_pad() is useful for managing lengths. Consider the common situation when zeros are dropped from the beginning of FIPS codes.\n\ntibble(fips = c(1, 2, 4)) |&gt;\n  mutate(fips = str_pad(fips, side = \"left\", pad = \"0\", width = 2))\n\n# A tibble: 3 × 1\n  fips \n  &lt;chr&gt;\n1 01   \n2 02   \n3 04   \n\n\n\n\nModifying Strings\nstr_replace(), str_replace_all(), str_remove(), and str_remove_all() can delete or modify parts of strings. Consider an example where we have course names and we want to delete everything except numeric digits.2\n\ntibble(course = c(\"PPOL 670\", \"GOVT 8009\", \"PPOL 6819\")) |&gt;\n  mutate(course = str_remove(course, pattern = \"[:alpha:]*\\\\s\"))\n\n# A tibble: 3 × 1\n  course\n  &lt;chr&gt; \n1 670   \n2 8009  \n3 6819  \n\n\nstr_c() and str_glue() are useful for joining strings. Consider an example where we want to “fill in the blank” with a variable in a data frame.\n\ntibble(fruit = c(\"apple\", \"banana\", \"cantelope\")) |&gt;\n  mutate(sentence = str_glue(\"my favorite fruit is {fruit}\"))\n\n# A tibble: 3 × 2\n  fruit     sentence                      \n  &lt;chr&gt;     &lt;glue&gt;                        \n1 apple     my favorite fruit is apple    \n2 banana    my favorite fruit is banana   \n3 cantelope my favorite fruit is cantelope\n\n\n\ntibble(fruit = c(\"apple\", \"banana\", \"cantelope\")) |&gt;\n  mutate(\n    another_sentence = \n      str_c(\"Who doesn't like a good \", fruit, \".\")\n    )\n\n# A tibble: 3 × 2\n  fruit     another_sentence                  \n  &lt;chr&gt;     &lt;chr&gt;                             \n1 apple     Who doesn't like a good apple.    \n2 banana    Who doesn't like a good banana.   \n3 cantelope Who doesn't like a good cantelope.\n\n\nThis workflow is useful for building up URLs when accessing APIs, scraping information from the Internet, and downloading many files.\n\n\n\n\n\n\nExercise 4\n\n\n\n\nUse mutate() and library(stringr) to create a variable for year from the earlier SOI exercise. For instance, \"agi2006\" should be \"2006\".\nUse as.numeric() to convert the string from step 1 into a numeric value.\nCreate a data visualization with year on the x-axis.\n\n\n\n\n\n\n2.4.2 Factors\nCheck out the forcats cheat sheet.\nMuch of our work focuses on four of the six types of atomic vectors: logical, integer, double, and character. R also contains augmented vectors like factors.\nFactors are categorical data stored as integers with a levels attribute. Character vectors often work well for categorical data and many of R’s functions convert character vectors to factors. This happens with lm().\nFactors have many applications:\n\nGiving the levels of a categorical variable non-alpha numeric order in a ggplot2 data visualization.\nRunning calculations on data with empty groups.\nRepresenting categorical outcome variables in classification models.\n\n\nFactor Basics\n\nx1 &lt;- factor(c(\"a\", \"a\", \"b\", \"c\"), levels = c(\"d\", \"c\", \"b\", \"a\"))\n\nx1\n\n[1] a a b c\nLevels: d c b a\n\nattributes(x1)\n\n$levels\n[1] \"d\" \"c\" \"b\" \"a\"\n\n$class\n[1] \"factor\"\n\nlevels(x1)\n\n[1] \"d\" \"c\" \"b\" \"a\"\n\n\nx1 has order but it isn’t ordinal. Sometimes we’ll come across ordinal factor variables, like with the diamonds data set. Unintentional ordinal variables can cause unexpected errors. For example, including ordinal data as predictors in regression models will lead to different estimated coefficients than other variable types.\n\nglimpse(diamonds)\n\nRows: 53,940\nColumns: 10\n$ carat   &lt;dbl&gt; 0.23, 0.21, 0.23, 0.29, 0.31, 0.24, 0.24, 0.26, 0.22, 0.23, 0.…\n$ cut     &lt;ord&gt; Ideal, Premium, Good, Premium, Good, Very Good, Very Good, Ver…\n$ color   &lt;ord&gt; E, E, E, I, J, J, I, H, E, H, J, J, F, J, E, E, I, J, J, J, I,…\n$ clarity &lt;ord&gt; SI2, SI1, VS1, VS2, SI2, VVS2, VVS1, SI1, VS2, VS1, SI1, VS1, …\n$ depth   &lt;dbl&gt; 61.5, 59.8, 56.9, 62.4, 63.3, 62.8, 62.3, 61.9, 65.1, 59.4, 64…\n$ table   &lt;dbl&gt; 55, 61, 65, 58, 58, 57, 57, 55, 61, 61, 55, 56, 61, 54, 62, 58…\n$ price   &lt;int&gt; 326, 326, 327, 334, 335, 336, 336, 337, 337, 338, 339, 340, 34…\n$ x       &lt;dbl&gt; 3.95, 3.89, 4.05, 4.20, 4.34, 3.94, 3.95, 4.07, 3.87, 4.00, 4.…\n$ y       &lt;dbl&gt; 3.98, 3.84, 4.07, 4.23, 4.35, 3.96, 3.98, 4.11, 3.78, 4.05, 4.…\n$ z       &lt;dbl&gt; 2.43, 2.31, 2.31, 2.63, 2.75, 2.48, 2.47, 2.53, 2.49, 2.39, 2.…\n\n\n\nx2 &lt;- factor(\n  c(\"a\", \"a\", \"b\", \"c\"), \n  levels = c(\"d\", \"c\", \"b\", \"a\"),\n  ordered = TRUE\n)\n\nx2\n\n[1] a a b c\nLevels: d &lt; c &lt; b &lt; a\n\nattributes(x2)\n\n$levels\n[1] \"d\" \"c\" \"b\" \"a\"\n\n$class\n[1] \"ordered\" \"factor\" \n\nlevels(x2)\n\n[1] \"d\" \"c\" \"b\" \"a\"\n\n\nFigure 2.1 shows how we can use a factor to give a variable a non-alpha numeric order and preserve empty levels. In this case, February and March have zero tropical depressions, tropical storms, and hurricanes and we want to demonstrate that emptiness.\n\n# use case_match to convert integers into month names\nstorms &lt;- storms |&gt;\n  mutate(\n    month = case_match(\n      month,\n      1 ~ \"Jan\",\n      4 ~ \"Apr\",\n      5 ~ \"May\",\n      6 ~ \"Jun\",\n      7 ~ \"Jul\",\n      8 ~ \"Aug\",\n      9 ~ \"Sep\",\n      10 ~ \"Oct\",\n      11 ~ \"Nov\",\n      12 ~ \"Dec\"\n    )\n  )\n\n# create data viz without factors\nstorms |&gt;\n  count(month) |&gt;\n  ggplot(aes(x = n, y = month)) +\n  geom_col()\n\n# add factor variable\nmonths &lt;- c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\n            \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\")\n\nstorms &lt;- storms |&gt;\n  mutate(month = factor(month, levels = months)) \n\n# create data viz with factors\nstorms |&gt;\n  count(month, .drop = FALSE) |&gt;\n  ggplot(aes(x = n, y = month)) +\n  geom_col()\n\n\n\n\n\n\n\n(a) Figure without a factor\n\n\n\n\n\n\n\n(b) Figure with a factor\n\n\n\n\nFigure 2.1: Hurricane Season Peaks in Late Summer and Early Fall\n\n\n\nFactors also change the behavior of summary functions like count().\n\nstorms |&gt;\n  count(month)\n\n# A tibble: 10 × 2\n   month     n\n   &lt;fct&gt; &lt;int&gt;\n 1 Jan      70\n 2 Apr      66\n 3 May     201\n 4 Jun     779\n 5 Jul    1603\n 6 Aug    4440\n 7 Sep    7509\n 8 Oct    3077\n 9 Nov    1109\n10 Dec     212\n\nstorms |&gt;\n  count(month, .drop = FALSE)\n\n# A tibble: 12 × 2\n   month     n\n   &lt;fct&gt; &lt;int&gt;\n 1 Jan      70\n 2 Feb       0\n 3 Mar       0\n 4 Apr      66\n 5 May     201\n 6 Jun     779\n 7 Jul    1603\n 8 Aug    4440\n 9 Sep    7509\n10 Oct    3077\n11 Nov    1109\n12 Dec     212\n\n\nlibrary(forcats) simplifies many common operations on factor vectors.\n\n\nChanging Order\nfct_relevel(), fct_rev(), and fct_reorder() are useful functions for modifying the order of factor variables. Figure 2.2 demonstrates using fct_rev() to flip the order of a categorical axis in ggplot2.\n\nstorms |&gt;\n  count(month, .drop = FALSE) |&gt;\n  ggplot(aes(x = n, y = month)) +\n  geom_col()\n\nstorms |&gt;\n  mutate(month = fct_rev(month)) |&gt;\n  count(month, .drop = FALSE) |&gt;\n  ggplot(aes(x = n, y = month)) +\n  geom_col()\n\n\n\n\n\n\n\n(a) Descending\n\n\n\n\n\n\n\n(b) Ascending\n\n\n\n\nFigure 2.2: Hurricane Season Peaks in Late Summer and Early Fall\n\n\n\nFigure 2.3 orders the factor variable based on the number of observations in each category using fct_reorder(). fct_reorder() can order variables based on more sophisticated summaries than just magnitude. For example, it can order box-and-whisker plots based on the median or even something as arbitrary at the 60th percentile.\n\nstorms |&gt;\n  count(month, .drop = FALSE) |&gt;\n  ggplot(aes(x = n, y = month)) +\n  geom_col()\n\nstorms |&gt;\n  count(month, .drop = FALSE) |&gt;\n  mutate(month = fct_reorder(.f = month, .x = n, .fun = median)) |&gt;\n  ggplot(aes(x = n, y = month)) +\n  geom_col()\n\n\n\n\n\n\n\n(a) Alpha-numeric\n\n\n\n\n\n\n\n(b) Magnitude\n\n\n\n\nFigure 2.3: Hurricane Season Peaks in Late Summer and Early Fall\n\n\n\n\n\nChanging Values\nFunctions like fct_recode() and fct_lump_min() are useful for changing factor variables. Figure 2.4 combines categories with fewer than 1,000 observations into an \"Other\" group.\n\nstorms |&gt;\n  count(month, .drop = FALSE) |&gt;\n  ggplot(aes(x = n, y = month)) +\n  geom_col()\n\nstorms |&gt;\n  mutate(month = fct_lump_min(month, min = 1000)) |&gt;  \n  count(month, .drop = FALSE) |&gt;\n  ggplot(aes(x = n, y = month)) +\n  geom_col()\n\n\n\n\n\n\n\n(a) All\n\n\n\n\n\n\n\n(b) Lumped\n\n\n\n\nFigure 2.4: Hurricane Season Peaks in Late Summer and Early Fall\n\n\n\n\n\n\n2.4.3 Dates and Date-Times\nCheck out the lubridate cheat sheet.\nThere are many ways to store dates.\n\nMarch 14, 1992\n03/14/1992\n14/03/1992\n14th of March ’92\n\nOne way of storing dates is the best. The ISO 8601 date format is an international standard with appealing properties like fixed lengths and self ordering. The format is YYYY-MM-DD.\nlibrary(lubridate) has useful functions that will take dates of any format and convert them to the ISO 8601 standard.\n\nlibrary(lubridate)\n\nmdy(\"March 14, 1992\")\n\n[1] \"1992-03-14\"\n\nmdy(\"03/14/1992\")\n\n[1] \"1992-03-14\"\n\ndmy(\"14/03/1992\")\n\n[1] \"1992-03-14\"\n\ndmy(\"14th of March '92\")\n\n[1] \"1992-03-14\"\n\n\nThese functions return variables of class \"Date\".\n\nclass(mdy(\"March 14, 1992\"))\n\n[1] \"Date\"\n\n\nlibrary(lubridate) also contains functions for parsing date times into ISO 8601 standard. Times are slightly trickier because of time zones.\n\nmdy_hms(\"12/02/2021 1:00:00\")\n\n[1] \"2021-12-02 01:00:00 UTC\"\n\nmdy_hms(\"12/02/2021 1:00:00\", tz = \"EST\")\n\n[1] \"2021-12-02 01:00:00 EST\"\n\nmdy_hms(\"12/02/2021 1:00:00\", tz = \"America/Chicago\")\n\n[1] \"2021-12-02 01:00:00 CST\"\n\n\nBy default, library(lubridate) will put the date times in Coordinated Universal Time (UTC), which is the successor to Greenwich Mean Time (GMT). I recommend carefully reading the data dictionary if time zones are important for your analysis or if your data cross time zones. This is especially important during time changes (e.g. “spring forward” and “fall back”).\nFortunately, if you encode your dates or date-times correctly, then library(lubridate) will automatically account for time changes, time zones, leap years, leap seconds, and all of the quirks of dates and times.\n\n\n\n\n\n\nExercise 5\n\n\n\n\ndates &lt;- tribble(\n  ~date,\n  \"12/01/1987\",\n  \"12/02/1987\",\n  \"12/03/1987\"\n)\n\n\nCreate the dates data from above with tribble().\nUse mutate() to convert the date column to the ISO 8601 standard.\n\n\n\n\nExtracting Components\nlibrary(lubridate) contains functions for extracting components from dates like the year, month, day, and weekday. Conisder the follow data set about full moons in Washington, DC in 2023.\n\nfull_moons &lt;- tribble(\n  ~full_moon,\n  \"2023-01-06\",\n  \"2023-02-05\",\n  \"2023-03-07\",\n  \"2023-04-06\",\n  \"2023-05-05\",\n  \"2023-06-03\",\n  \"2023-07-03\",\n  \"2023-08-01\",\n  \"2023-08-30\",\n  \"2023-09-29\",\n  \"2023-10-28\",\n  \"2023-11-27\",\n  \"2023-12-26\"\n) |&gt;\n  mutate(full_moon = as_date(full_moon))\n\nSuppose we want to know the weekday of each full moon.\n\nfull_moons |&gt;\n  mutate(week_day = wday(full_moon, label = TRUE))\n\n# A tibble: 13 × 2\n   full_moon  week_day\n   &lt;date&gt;     &lt;ord&gt;   \n 1 2023-01-06 Fri     \n 2 2023-02-05 Sun     \n 3 2023-03-07 Tue     \n 4 2023-04-06 Thu     \n 5 2023-05-05 Fri     \n 6 2023-06-03 Sat     \n 7 2023-07-03 Mon     \n 8 2023-08-01 Tue     \n 9 2023-08-30 Wed     \n10 2023-09-29 Fri     \n11 2023-10-28 Sat     \n12 2023-11-27 Mon     \n13 2023-12-26 Tue     \n\n\n\n\nMath\nlibrary(lubridate) easily handles math with dates and date-times. Suppose we want to calculate the number of days since American Independence Day:\n\ntoday() - as_date(\"1776-07-04\")\n\nTime difference of 90263 days\n\n\nIn this case, subtraction creates an object of class difftime represented in days. We can use the difftimes() function to calculate differences in other units.\n\ndifftime(today(), as_date(\"1776-07-04\"), units = \"mins\")\n\nTime difference of 129978720 mins\n\n\n\n\nPeriods\nPeriods track clock time or a calendar time. We use periods when we set a recurring meetings on a calendar and when we set an alarm to wake up in the morning.\nThis can lead to some interesting results. Do we always add 365 days when we add 1 year to a date? With periods, this isn’t true. Sometimes we add 366 days during leap years. For example,\n\nstart &lt;- as_date(\"1999-03-14\")\nend &lt;- start + years(1)\n\nend\n\n[1] \"2000-03-14\"\n\nend - start\n\nTime difference of 366 days\n\n\n\n\nDurations\nDurations track the passage of physical time in exact seconds. Durations are like sand falling into an hourglass. Duration functions start with d like dyears() and dminutes().\n\nstart &lt;- as_date(\"1999-03-14\")\nend &lt;- start + dyears(1)\n\nend\n\n[1] \"2000-03-13 06:00:00 UTC\"\n\n\nNow we always add 365 days, but we see that March 13th is one year after March 14th.\n\n\nIntervals\nUntil now, we’ve focused on points in time. Intervals have length and have a starting point and an ending point.\nSuppose classes start on August 23rd and proceed every week for a while. Do any of these dates conflict with Georgetown’s fall break?\n\nclasses &lt;- as_date(\"2023-08-23\") + weeks(0:15)\n\nfall_break &lt;- interval(as_date(\"2023-11-22\"), as_date(\"2023-11-26\"))\n\nclasses %within% fall_break\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[13] FALSE  TRUE FALSE FALSE\n\n\nWe focused on dates, but many of the same principles hold for date-times.\n\n\n\n\n\n\nExercise 6\n\n\n\n\nCreate a date object for your birth date.\nCalculate the number of days since your birth date.\nCreate a vector of your birthdays from your birth date for the next 120 years. Do you use periods or durations?\n\n\n\n\n\n\n2.4.4 Missing Data\nMissing data are ever present in data analysis. R stores missing values as NA, which are contagious and are fortunately difficult to ignore.\nreplace_na() is the quickest function to replace missing values. It is a shortcut for a specific instance of if_else().\n\nx &lt;- c(1, NA, 3)\n\nif_else(condition = is.na(x), true = 2, false = x)\n\n[1] 1 2 3\n\nreplace_na(x, replace = 2)\n\n[1] 1 2 3\n\n\nWe recommend avoiding arguments like na.rm and using filter() for structurally missing values and replace_na() or imputation for nonresponse.\n\n\n\n\n\n\nExercise 7\n\n\n\nLet’s focus on different data shared by SOI. Now we’ll focus on individual income and tax data by state.\nThis Excel workbook is a beast. For instance, it isn’t clear how the hierarchy works. I expected all of the rows nested under “Number of returns” to sum up to the number of returns. Unfortunately, the rows are not disjoint. Also, the merged cells for column headers are very difficult to use with programming languages.\n\nStart with 20in01al.xlsx.\nCreate a tidy data frame with rows 10 through 12 (“Number of single returns”, “Number of joint returns”, and “Number of head of household returns”) disaggregated by “size of adjusted gross income”."
  },
  {
    "objectID": "02_advanced-data-cleaning.html#footnotes",
    "href": "02_advanced-data-cleaning.html#footnotes",
    "title": "2  Advanced Data Cleaning",
    "section": "",
    "text": "The instinct to include these comments is good. The execution is poor because it creates big headaches for people using programming languages. I suggest using a data dictionary instead.↩︎\nThis example uses regular expressions (regex). Visit R4DS (2e) for a review of regex.↩︎"
  }
]