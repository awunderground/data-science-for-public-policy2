[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Science for Public Policy Part II",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "01_advanced-quarto.html#sec-review",
    "href": "01_advanced-quarto.html#sec-review",
    "title": "1  Advanced Quarto",
    "section": "1.1 Review",
    "text": "1.1 Review\n\n1.1.1 Motivation\nThere are many problems worth avoiding in an analysis:\n\nCopying-and-pasting, transposing, and manual repetition\nRunning code out-of-order\nMaintaining parallel documents like a script for analysis and a doc for narrative\nCode written for computers that is tough to parse by humans\n\nNot convinced? Maybe we just want to make cool stuff like websites, blogs, books, and slide decks.\nQuarto, a literate statistical programming framework for R, Python, and Julia helps us solve many of these problems. Quarto uses\n\nplain text files ending in .qmd that are similar to .R and .Rmd files\nlibrary(knitr)\npandoc1\n\nQuarto uses library(knitr) and pandoc to convert plain text .qmd documents into rich output documents like these class notes. The “Render” button appears in RStudio with a .qmd file is open in the editor window.\nClicking the “Render” button begins the process of rendering .qmd files.\n\n\n\n\n\n\n\n\n\nWhen the button is clicked, Quarto calls library(knitr) and renders .qmd (Quarto files) into .md (Markdown files), which Pandoc then converts into any specified output type. Quarto and library(knitr) don’t need to be explicitly loaded as the entire process is handled by clicking the “Render” button in RStudio.\n\n\n\n\n\n\n\n\n\nSource: Quarto website\nQuarto, library(knitr), and Pandoc are all installed with RStudio. You will need to install a LaTeX distribution to render PDFs. We recommend library(tinytex) as a LaTeX distribution (installation instructions).\n\n\n\n\n\n\nExercise 1\n\n\n\n\nClick the new script button in RStudio and add a “Quarto Document”.\nGive the document a name, an author, and ensure that HTML is selected.\nSave the document as “hello-quarto.qmd”.\nClick “Render”.\n\n\n\nQuarto has three main ingredients:\n\nYAML header\nMarkdown text\nCode chunks\n\n\n\n1.1.2 (1) YAML Header\nYAML stands for “yet another markup language”. The YAML header contains meta information about the document including output type, document settings, and parameters that can be passed to the document. The YAML header starts with --- and ends with ---.\nHere is the simplest YAML header for a PDF document:\n---\nformat: pdf\n---\nYAML headers can contain many output specific settings. This YAML header creates an HTML document with code folding and a floating table of contents:\n---\nformat: \n  html:\n    embed-resources: true\n    code-fold: true\n    toc: true\n---  \nParameters can be specified as follows\n---\nformat: pdf\nparams:\n  state: \"Virginia\"\n---\nNow state can be referred to anywhere in R code as params$state. Parameters are useful for a couple of reasons:\n\nWe can clearly change key values for a Quarto document in the YAML header.\nWe can create a template and programmatically iterate the template over a set of values with the quarto_render() function and library(purrr). This blog outlines the idea. The Mobility Metrics Data Tables and SLFI State Fiscal Briefs are key examples of this workflow.\n\n\n\n\n\n\n\nWarning\n\n\n\nUnlike R Markdown, images and other content are not embedded in .html from Quarto by default. Be sure to include embed-resources: true in YAML headers to embed content and make documents easier to share.\nSuppose we embed an image called image.png in a Quarto document called example.qmd, which, when rendered, creates example.html. If we don’t include embed-resources: true, then we will need to share image.png and example.html to see the embedded image. This is also true for other files like .css.\n\n\n\n\n1.1.3 (2) Markdown text\nMarkdown is a shortcut for HyperText Markup Language (HTML). Essentially, simple meta characters corresponding to formatting are added to plain text.\nTitles and subtitltes\n------------------------------------------------------------\n\n# Title 1\n\n## Title 2\n\n### Title 3\n\n\nText formatting \n------------------------------------------------------------\n\n*italic*  \n\n**bold**   \n\n`code`\n\nLists\n------------------------------------------------------------\n\n* Bulleted list item 1\n* Item 2\n  * Item 2a\n  * Item 2b\n\n1. Item 1\n2. Item 2\n\nLinks and images\n------------------------------------------------------------\n\n[text](http://link.com)\n\n![Penguins](images/penguins.png)\n\n\n1.1.4 (3) Code chunks\n\n\n\n\n\nMore frequently, code is added in code chunks:\n\n```{r}\n2 + 2\n```\n\n[1] 4\n\n\nThe first argument inline or in a code chunk is the language engine. Most commonly, this will just be a lower case r. knitr allows for many different language engines:\n\nR\nJulia\nPython\nSQL\nBash\nRcpp\nStan\nJavascript\nCSS\n\nQuarto has a rich set of options that go inside of the chunks and control the behavior of Quarto.\n\n```{r}\n#| label: important-calculation\n#| eval: false\n\n2 + 2\n```\n\nIn this case, eval makes the code not run. Other chunk-specific settings can be added inside the brackets. Here2 are the most important options:\n\n\n\nOption\nEffect\n\n\n\n\necho: false\nHides code in output\n\n\neval: false\nTurns off evaluation\n\n\noutput: false\nHides code output\n\n\nwarning: false\nTurns off warnings\n\n\nmessage: false\nTurns off messages\n\n\nfig-height: 8\nChanges figure width in inches3\n\n\nfig-width: 8\nChanges figure height in inches4\n\n\n\nYou can see the quarto defaults for figure dimensions by format here.\nDefault settings for the entire document can be changed in the YAML header with the execute option:\nexecute:\n  warning: false\n\n\n\n\n\n\nExercise 2\n\n\n\n\nAdd date: today to your YAML header after title. This will update every time the document is rendered.\nCopy the Markdown table from this table generator and add it to your .qmd document.\nCreate a scatter plot of the cars data with library(ggplot2). Adjust the figure width and height using options within the chunk.\nClick “Render”.\n\n\n\n\n\n1.1.5 Organizing a Quarto Document\nIt is important to clearly organize a Quarto document and the constellation of files that typically support an analysis.\n\nAlways use .Rproj files.\nUse sub-directories to sort images, .css, data.\n\nLater, we will learn how to use library(here) to effectively organize sub-directories."
  },
  {
    "objectID": "01_advanced-quarto.html#math-notation",
    "href": "01_advanced-quarto.html#math-notation",
    "title": "1  Advanced Quarto",
    "section": "1.2 Math Notation",
    "text": "1.2 Math Notation\nThis course uses probability and statistics. Occasionally, we want to easily communicate with mathematical notation. For example, it may be convenient to type that \\(X\\) is a random variable that follows a standard normal distribution (mean = 0 and standard deviation = 1).\n\\[X \\sim N(\\mu = 0, \\sigma = 1)\\]\n\n1.2.1 Math Mode\nUse $ to start and stop in-line math notation and $$ to start multi-line math notation. Math notation uses LaTeX’s syntax for mathematical notation.\nHere’s an example with in-line math:\nConsider a binomially distributed random variable, $X \\sim binom(n, p)$. \nConsider a binomially distributed random variable, \\(X \\sim binom(n, p)\\).\nHere’s an example with a chunk of math:\n$$\nP(X = x) = {n \\choose x} p ^ x (1 - p) ^ {n - x}\n$${#eq-binomial}\n\\[\nP(X = x) = {n \\choose x} p ^ x (1 - p) ^ {n - x}\n\\tag{1.1}\\]\n\n\n1.2.2 Important Syntax\nMath mode recognizes basic math symbols available on your keyboard including +, -, *, /, &gt;, &lt;, (, and ).\nMath mode contains all greek letters. For example, \\alpha (\\(\\alpha\\)) and \\beta (\\(\\beta\\)).\n\n\nTable 1.1: My Caption\n\n\nLaTeX\nSymbol\n\n\n\n\n\\alpha\n\\(\\alpha\\)\n\n\n\\beta\n\\(\\beta\\)\n\n\n\\gamma\n\\(\\gamma\\)\n\n\n\\Delta\n\\(\\Delta\\)\n\n\n\\epsilon\n\\(\\epsilon\\)\n\n\n\\theta\n\\(\\theta\\)\n\n\n\\pi\n\\(\\pi\\)\n\n\n\\sigma\n\\(\\sigma\\)\n\n\n\\chi\n\\(\\chi\\)\n\n\n\n\nMath mode also recognizes \\(\\log(x)\\) (\\log(x)) and \\(\\sqrt{x}\\) (\\sqrt{x}).\nSuperscripts (^) are important for exponentiation and subscripts (_) are important for adding indices. y = x ^ 2 renders as \\(y = x ^ 2\\) and x_1, x_2, x_3 renders as \\(x_1, x_2, x_3\\). Brackets are useful for multi-character superscripts and subscripts like \\(s_{11}\\) (s_{11}).\nIt is useful to add symbols to letters. For example, \\bar{x} is useful for sample means (\\(\\bar{x}\\)), \\hat{y} is useful for predicted values (\\(\\hat{y}\\)), and \\vec{\\beta} is useful for vectors of coefficients (\\(\\vec{\\beta}\\)).\nMath mode supports fractions with \\frac{x}{y} (\\(\\frac{x}{y}\\)), big parentheses with \\left(\\right) (\\(\\left(\\right)\\)), and brackets with \\left[\\right] (\\(\\left[\\right]\\)).\nMath mode has a symbol for summation. Let’s combine it with bars, fractions, subscripts, and superscipts to show sample mean \\bar{x} = \\frac{1}{n}\\sum_i^n x_i, which looks like \\(\\bar{x} = \\frac{1}{n}\\sum_i^n x_i\\).\n\\sim is how to add the tilde for distributed as. For example, X \\sim N(\\mu = 0, \\sigma = 1) shows the normal distribution \\(X \\sim N(\\mu = 0, \\sigma = 1)\\).\nMatrices are are a little bit more work in math mode. Consider the follow variance-covariance matrix:\n\\begin{bmatrix}\ns_{11}^2 & s_{12}\\\\\ns_{21} & s_{22}^2\n\\end{bmatrix}\n\\[\n\\begin{bmatrix}\ns_{11}^2 & s_{12}\\\\\ns_{21} & s_{22}^2\n\\end{bmatrix}\n\\]\nThis guide provides and exhaustive look at math options in Quarto.\n\n\n\n\n\n\nWarning\n\n\n\nMath mode is finicky! Small errors like mismatched parentheses or superscript and subscript errors will cause Quarto documents to fail to render. Write math carefully and render early and often.\n\n\n\n\n\n\n\n\nExercise 3\n\n\n\n\nUse math mode to type out the equation for root mean square error (RMSE).\nDo you divide by n or n - 1?"
  },
  {
    "objectID": "01_advanced-quarto.html#cross-references",
    "href": "01_advanced-quarto.html#cross-references",
    "title": "1  Advanced Quarto",
    "section": "1.3 Cross References",
    "text": "1.3 Cross References\nCross references are useful for organizing documents that include sections, figures, tables, and equations. Cross references create hyperlinks within documents that jump to the locations of these elements. Linking sections, figures, tables, or equations helps readers navigate the document.\nCross references also automatically number the referenced elements. This means that if there are two tables (ie. Table 1 and Table 2) and a table is added between the two tables, all of the table numbers and references to the tables will automatically update.\nCross references require two bits of code within a Quarto document:\n\nA label associated with the section, figure, table, or equation.\nA reference to the labelled section, figure, table, or equation.\n\nLabels are written in brackets or as arguments in code chunks, and begin with the the type object being linked. References begin with @ followed by the label of object being linked.\n\n1.3.1 Sections\nLinking sections helps readers navigate between sections. Use brackets to label sections after headers and always begin labels with sec-. Then you can reference that section with @sec-.\n## Review {sec-review}\n\nSee @sec-review if you are totally lost.\nThe cross references shows up like this: See Section 1.1 if you are totally lost.\nIt can be helpful to turn on section numbering with number-sections: true in the YAML header. Additionally, Markdown has a native method for linking between sections.\n\n\n\n\n\n\nExercise 4\n\n\n\n\nAdd a few section headers to your Quarto document.\nAdd a cross reference to one of the section headers.\n\n\n\n\n\n1.3.2 Figures\n\n\n\nFigure 1.1: Penguins\n\n\nWe can reference figures like Figure 1.1 with @fig-penguins.\n\n\n1.3.3 Tables\nWe can link to tables in our documents. For example, we can link to the greek table with @tbl-greek Table 1.1.\n\n\n1.3.4 Equations\nWe can link to equations in our documents. For example, we can link to the binomial distribution earlier with @eq-binomial Equation 1.1.\n\n\n\n\n\n\nExercise 5\n\n\n\n\nAdd a cross reference to your RMSE equation from earlier."
  },
  {
    "objectID": "01_advanced-quarto.html#citations",
    "href": "01_advanced-quarto.html#citations",
    "title": "1  Advanced Quarto",
    "section": "1.4 Citations",
    "text": "1.4 Citations\n\n1.4.1 Zotero\nZotero is a free and open-source software for organizing research and managing citations.\n\n\n\n\n\n\nDigital Object Identifier (DOI)\n\n\n\nDOIs are persistent identifiers that uniquely identify objects including many academic papers. For example, 10.1198/jcgs.2009.07098 identifies “A Layered Grammar of Graphics” by Hadley Wickham.\n\n\n\n\n\n\n\n\nExercise 6\n\n\n\n\nInstall Zotero.\nFind the DOI for “Tidy Data” by Hadley Wickham.\nClick the magic wand in Zotero and paste the DOI.\n\n\n\n\n\n\n\n\n\n\n\nReview the new entry in Zotero.\n\n\n\n\n\n1.4.2 Zotero Integration\nZotero has a powerful integration with Quarto. In practice, it’s one click to add a DOI to Zotero and then one click to add a citation to Quarto.\nRStudio automatically adds My Library from Zotero. Simply switch to the Visual Editor (top left in RStudio), click “Insert”, and click “Citation”. This will open a prompt to insert a citation into the Quarto document.\nThe citation is automatically added with parentheses to go at the end of sentences. Delete the square brackets to convert the citation to an in-line citation.\nInserting the citation automatically adds the citation to the references section. Deleting the reference automatically deletes the citation from the references section.\nZotero Groups are useful for sharing citations and Zotero Group Libraries need to be added to RStudio. To set this up:\nTo set this up, in RStudio:\n\nGo to Tools and select “Global Options”\nSelect “RMarkdown” and then click “Citations”\nFor “Use Libraries” choose “Selected Libraries”\nSelect the group libraries to add\n\n\n\n\n\n\n\nExercise 7\n\n\n\n\nCite “Tidy Data” by Hadley Wickham in your Quarto document.\nClick “Render”"
  },
  {
    "objectID": "01_advanced-quarto.html#more-resources",
    "href": "01_advanced-quarto.html#more-resources",
    "title": "1  Advanced Quarto",
    "section": "1.5 More Resources",
    "text": "1.5 More Resources\n\nQuarto Guide\nIterating fact sheets and web pages with Quarto"
  },
  {
    "objectID": "01_advanced-quarto.html#footnotes",
    "href": "01_advanced-quarto.html#footnotes",
    "title": "1  Advanced Quarto",
    "section": "",
    "text": "Pandoc is free software that converts documents between markup formats. For example, Pandoc can convert files to and from markdown, LaTeX, jupyter notebook (ipynb), and Microsoft Word (.docx) formats, among many others. You can see a comprehensive list of files Pandoc can convert on their About Page.↩︎\nThis table was typed as Markdown code. But sometimes it is easier to use a code chunk to create and print a table. Pipe any data frame into knitr::kable() to create a table that will be formatted in the output of a rendered Quarto document.↩︎\nThe default dimensions for figures change based on the output format. Visit here to learn more.↩︎\nThe default dimensions for figures change based on the output format. Visit here to learn more.↩︎"
  },
  {
    "objectID": "06_advanced-unsupervised-ml.html#sec-review6",
    "href": "06_advanced-unsupervised-ml.html#sec-review6",
    "title": "2  Mixture Distributions and Mixture Models",
    "section": "2.1 Review 1",
    "text": "2.1 Review 1\nsample from a distribution"
  },
  {
    "objectID": "06_advanced-unsupervised-ml.html#a-new-type-of-random-variable",
    "href": "06_advanced-unsupervised-ml.html#a-new-type-of-random-variable",
    "title": "2  Mixture Distributions and Mixture Models",
    "section": "2.2 A New Type of Random Variable",
    "text": "2.2 A New Type of Random Variable\n\n\n\n\n\n\nLatent Variable\n\n\n\n\n\n\ndefine: latent variable\nWe learned about common univariate and multivariate distributions. For each of the distributions, there are well-defined and straightfoward ways to sample values from the distribution.\nLet’s consider a slightly different “data generation story” where we sample in two stages. (Data generation story from ESL [273])\n\nSample from a discrete probability distribution with \\(k\\) unique values (i.e. Bernoulli distribution when \\(k = 2\\) and categorical distribution when \\(k &gt; 2\\)).\nSample from one of \\(k\\) different distributions conditional on the outcome of step 1.\n\nLet’s consider a concrete example with a Bernoulli distribution and two normal distributions.\n\nSample \\(X \\sim Bern(p = 0.25)\\)\nSample from \\(Y \\sim N(\\mu = 0, \\sigma = 2)\\) if \\(X = 0\\) and \\(Y \\sim (\\mu = 4, \\sigma = 2)\\) if \\(X = 1\\).\n\nNow, let’s sample from a Bernoulli distribution and then sample from one of two normal distributions using R code.\n\ngenerate_data &lt;- function(n) {\n  \n  step1 &lt;- sample(x = c(0, 1), size = n, replace = TRUE, prob = c(0.75, 0.25))\n  \n  step1 &lt;- sort(step1)\n  \n  step2 &lt;- c(\n    rnorm(n = sum(step1 == 0), mean = 0, sd = 2),\n    rnorm(n = sum(step1 == 1), mean = 5, sd = 1)\n  )\n  \n  tibble::tibble(\n    x = step1,\n    y = step2\n  )\n\n}\n\nset.seed(1)\n\ngenerate_data(n = 1000) %&gt;%\n  ggplot(aes(y)) +\n  geom_density() #+\n\n\n\n  # geom_density(aes(color = factor(x)))\n\nThis marginal distribution looks complex but the process of creating the marginal distribution is simple.\nThis two-step approach dramatically increases the types of distributions at our disposal because we are no longer limited to common univariate distributions like the normal distribution and uniform distribution. The two-step approach is also the foundation of two related tools:\n\nMixture distributions: Distributions expressed as the linear combination of other distributions. Mixture distributions can be very complicated distributions expressed in terms of simple distributions with known properties.\nMixture models: Statistical inference about sub-populations made only with pooled data without labels for the sub populations.\n\nWith mixture distributions, we care about the overall distribution and don’t care about the latent variables.\nWith mixture modeling, we use the overall distribution to learn about the latent variables/subpopulations/clusters in the data.\nancestral sampling: sample z_hat, sample x_hat|z_hat"
  },
  {
    "objectID": "06_advanced-unsupervised-ml.html#mixture-distribution",
    "href": "06_advanced-unsupervised-ml.html#mixture-distribution",
    "title": "2  Mixture Distributions and Mixture Models",
    "section": "2.3 Mixture Distribution",
    "text": "2.3 Mixture Distribution\nDefine mixture density\n“complex marginal distributions can be expressed as the joint distribution of observed and latent variables”\nGeysers data (Bishop, Hands On ML in R, )"
  },
  {
    "objectID": "06_advanced-unsupervised-ml.html#review-2",
    "href": "06_advanced-unsupervised-ml.html#review-2",
    "title": "2  Mixture Distributions and Mixture Models",
    "section": "2.4 Review #2",
    "text": "2.4 Review #2\nmultivariate-normal distribution\nReview K-Means Clustering\nhard assignments"
  },
  {
    "objectID": "06_advanced-unsupervised-ml.html#mixture-modelsmodel-based-clustering",
    "href": "06_advanced-unsupervised-ml.html#mixture-modelsmodel-based-clustering",
    "title": "2  Mixture Distributions and Mixture Models",
    "section": "2.5 Mixture Models/Model-Based Clustering",
    "text": "2.5 Mixture Models/Model-Based Clustering\n\n2.5.1 Gaussian Mixture Modeling (GMM)\nparameters: means, covariance matrices, mixture weights/mixture proportions\nover parameterized\nsoft assignments responsibility\nchallenges: 1. assumes a model 2. computation – overparameterized\n\nlibrary(censusapi)\n\nWarning: package 'censusapi' was built under R version 4.1.2\n\n\n\nAttaching package: 'censusapi'\n\n\nThe following object is masked from 'package:methods':\n\n    getFunction\n\nus_youth_sahie &lt;- getCensus(\n  name = \"timeseries/healthins/sahie\",\n  vars = c(\"GEOID\", \"PCTUI_PT\"),\n  region = \"county:*\",\n  regionin = \"state:*\",\n  time = 2019,\n  AGECAT = 4\n)\n\n\n\n2.5.2 EM\nESL has a good explanation\n\n\n2.5.3 BIC\nLikelihood: The likelihood is how probable observed data are given a set of parameters. If \\(\\theta\\) is a vector of parameters, then \\(L(\\theta |x) = f(x |\\theta)\\) is the likelihood function. The likelihood is not a probability. In fact, we often take the log of the likelihood for computational reasons.\nFor example, the likelihood of \\(x = ?\\) is blank given $X_i N(0, 1)\nThe Bayesian information criterion, or BIC, is a version of the likelihood that penalizes models for having many parameters.\nexplain Log-Likelihood explain BIC maximize BIC!\n\n\n2.5.4 Example\nMedicaid expansion Geyser data\n\n\n2.5.5 Bernoulli Mixture Modeling (BMM)\nLet’s consider a data generation story based on the Bernoulli distribution. Now, each variable, \\(X_1, X_2, ..., X_D\\), is draw from a mixture of \\(K\\) Bernoulli distributions.\n\\[\nX_d  = \\begin{cases}\nBern(p_1) \\text{ with probability }\\pi_1 \\\\\nBern(p_2) \\text{ with probability }\\pi_2 \\\\\n\\vdots \\\\\nBern(p_K) \\text{ with probability }\\pi_K\n\\end{cases}\n\\tag{2.1}\\]\nLet \\(i\\) be an index for each mixture that contributes to the random variable. The probability mass function of the random variable is written as\n\\[\nP(X_d) = \\Pi_{i = 1}^Kp_i^{x_i} (1 - p_i)^{1 - x_i}\n\\tag{2.2}\\]\nLet’s consider a classic example from Bishop (2006) and Murphy (2022). The example uses the MNIST database, which contains 70,000 handwritten digits. The digits are stored in 784 variables, from a 28 by 28 grid, with values ranging from 0 to 255, which indicates the darkness of the pixel.\nTo prepare the data, we divide each pixel by 255 and then turn the pixels into indicators with values under 0.5 as 0 and values over 0.5 as 1. Let’s read in the data and the visualize the first row of the data.\n\nsource(here::here(\"R\", \"visualize_digit.R\"))\n\nmnist &lt;- read_csv(here::here(\"data\", \"mnist_binary.csv\"))\n\nglimpse(select(mnist, 1:10))\n\nRows: 60,000\nColumns: 10\n$ label    &lt;dbl&gt; 5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4…\n$ pix_28_1 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ pix_28_2 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ pix_28_3 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ pix_28_4 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ pix_28_5 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ pix_28_6 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ pix_28_7 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ pix_28_8 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ pix_28_9 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\nFigure 2.1 shows the first four digits in the data after pre-processing.\n\nvisualize_digit(mnist, 1)\nvisualize_digit(mnist, 2)\nvisualize_digit(mnist, 3)\nvisualize_digit(mnist, 4)\n\n\n\n\n\n\n\n(a) 5\n\n\n\n\n\n\n\n(b) 0\n\n\n\n\n\n\n\n(c) 4\n\n\n\n\n\n\n\n(d) 1\n\n\n\n\nFigure 2.1: First Four Digits\n\n\n\nThe digits are labelled in the MNIST data set but we will ignore the labels and use Bernoulli Mixture Modeling as an unsupervised method. We will treat each pixel as it’s own Bernoulli distribution and cluster observations based mixtures of 784 Bernoulli distributions. This means each cluster will contain \\(784K\\) parameters.\n\n\n2.5.6 Two Digit Example\nLet’s start with a simple example using just the digits “1” and “8”. We’ll use library(flexmix) by Leisch (2004). library(flexmix) is powerful but uses different syntax than we are used to.\n\nThe function flexmix() expects a matrix.\nThe formula expects the entire matrix on the left side of the ~.\nWe specify the distribution used during the maximization (M) step with model = FLXMCmvbinary().\n\n\nlibrary(flexmix)\n\nWarning: package 'flexmix' was built under R version 4.1.2\n\n\nLoading required package: lattice\n\nmnist_18 &lt;- mnist |&gt;\n  filter(label %in% c(\"1\", \"8\")) |&gt;\n  select(-label) |&gt;\n  as.matrix()\n\nThe starting assignments are random, so we set a seed.\n\nset.seed(20230612)\nmnist_18_clust &lt;- flexmix(\n  formula = mnist_18 ~ 1, \n  k = 2, \n  model = FLXMCmvbinary(), \n  control = list(iter.max = 100)\n)\n\nThe MNIST data are already labelled, so we can compare our assignments to the labels if we convert the “soft assignments” to “hard assignments”. Note that most applications won’t have labels.\n\nmnist |&gt;\n  filter(label %in% c(\"1\", \"8\")) |&gt;  \n  bind_cols(cluster = mnist_18_clust@cluster) |&gt;\n  count(label, cluster)\n\n# A tibble: 4 × 3\n  label cluster     n\n  &lt;dbl&gt;   &lt;int&gt; &lt;int&gt;\n1     1       1   482\n2     1       2  6260\n3     8       1  5610\n4     8       2   241\n\n\nFigure 2.2 shows the estimated \\(p_i\\) for each pixel for each cluster. The following visualize the \\(784K\\) parameters that we estimated. It shows 784 \\(p_i\\) for \\(k = 1\\) and 784 \\(p_i\\) for \\(k = 2\\). We see that the estimated parameters closely resemble the digits.\n\nmeans_18 &lt;- rbind(\n  t(parameters(mnist_18_clust, component = 1)),\n  t(parameters(mnist_18_clust, component = 2))\n) |&gt;\n  as_tibble() |&gt;\n  mutate(label = NA)\n\n\nvisualize_digit(means_18, 1)\nvisualize_digit(means_18, 2)\n\n\n\n\n\n\n\n(a) 5\n\n\n\n\n\n\n\n(b) 0\n\n\n\n\nFigure 2.2: Estimated Parameters for Each Cluster\n\n\n\nThe BMM does a good job of labeling the digits and recovering the average shape of the digits.\n\n\n2.5.7 Ten Digit Example\nLet’s now consider an example that uses all 10 digits.\nIn most applications, we won’t know the number of latent variables. First, we sample 1,0001 digits and run the model with \\(k = 2, 3, ..., 20\\). We’ll calculate the BIC for each hyperparameter and pick the \\(k\\) with lowest BIC.\n\nset.seed(20230613)\nmnist_sample &lt;- mnist |&gt;\n  slice_sample(n = 1000) |&gt;\n  select(-label) |&gt;\n  as.matrix()\n\nsteps &lt;- stepFlexmix(\n  formula = mnist_sample ~ 1, \n  model = FLXMCmvbinary(), \n  control = list(iter.max = 100, minprior = 0),\n  k = 2:20, \n  nrep = 1\n)\n\nsteps\n\n\\(k = 7\\) provides the lowest BIC. This is probably because digits like 3 and 8 are very similar. Next, we run the BMM on the full data with \\(k = 7\\).\n\nmnist_full &lt;- mnist |&gt;\n  select(-label) |&gt;\n  as.matrix()\n\nmnist_clust &lt;- flexmix(\n  formula = mnist_full ~ 1, \n  k = 7, \n  model = FLXMCmvbinary(), \n  control = list(iter.max = 200, minprior = 0)\n)\n\nThe MNIST data are already labelled, so we can compare our assignments to the labels if we convert the “soft assignments” to “hard assignments”. Note that most applications won’t have labels.\n\nmnist |&gt;\n  bind_cols(cluster = mnist_clust@cluster) |&gt;\n  count(label, cluster) |&gt;\n  arrange(cluster)\n\n# A tibble: 69 × 3\n   label cluster     n\n   &lt;dbl&gt;   &lt;int&gt; &lt;int&gt;\n 1     0       1     1\n 2     1       1  6219\n 3     2       1   157\n 4     3       1   275\n 5     4       1    72\n 6     5       1    63\n 7     6       1   262\n 8     7       1   198\n 9     8       1   365\n10     9       1   123\n# ℹ 59 more rows\n\n\n?fig-bmm10-parameters shows the estimated \\(p_i\\) for each pixel for each cluster. It following visualize the \\(784K\\) parameters that we estimated. It shows 784 \\(p_i\\) for \\(k = 1, 2, ..., 7\\) clusters. We see that the estimated parameters closely resemble the digits.\n\nmeans &lt;- rbind(\n  t(parameters(mnist_clust, component = 1)),\n  t(parameters(mnist_clust, component = 2)),\n  t(parameters(mnist_clust, component = 3)),\n  t(parameters(mnist_clust, component = 4)),\n  t(parameters(mnist_clust, component = 5)),\n  t(parameters(mnist_clust, component = 6)),\n  t(parameters(mnist_clust, component = 7))\n) |&gt;\n  as_tibble() |&gt;\n  mutate(label = NA)\n\nvisualize_digit(means, 1)\nvisualize_digit(means, 2)\nvisualize_digit(means, 3)\nvisualize_digit(means, 4)\nvisualize_digit(means, 5)\nvisualize_digit(means, 6)\nvisualize_digit(means, 7)\n\n\n\n\n\n\nFigure 2.3: Estimated Parameters for Each Cluster\n\n\n\n\n\n\n\nFigure 2.4: Estimated Parameters for Each Cluster\n\n\n\n\n\n\n\nFigure 2.5: Estimated Parameters for Each Cluster\n\n\n\n\n\n\n\nFigure 2.6: Estimated Parameters for Each Cluster\n\n\n\n\n\n\n\n\n\nFigure 2.7: Estimated Parameters for Each Cluster\n\n\n\n\n\n\n\nFigure 2.8: Estimated Parameters for Each Cluster\n\n\n\n\n\n\n\nFigure 2.9: Estimated Parameters for Each Cluster\n\n\n\n\n\n\nThe example with all digits doesn’t result in 10 distinct mixtures but it does a fairly good job of structuring finding structure in the data. Without labels and considering the variety of messy handwriting, this is a useful model.\n\n\n2.5.8 More Examples?\nState human services typology\nemployed vs. unemployed vs. retired? yes/no on types of income\nshopping cart\n\nurl &lt;- \"https://koalaverse.github.io/homlr/data/my_basket.csv\"\nmy_basket &lt;- readr::read_csv(url)\n\nRows: 2000 Columns: 42\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (42): 7up, lasagna, pepsi, yop, red.wine, cheese, bbq, bulmers, mayonnai...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\nBishop, Christopher M. 2006. Pattern Recognition and Machine Learning. Information Science and Statistics. New York: Springer.\n\n\nLeisch, Friedrich. 2004. “FlexMix: A General Framework for Finite Mixture Models and Latent Class Regression in R.” Journal of Statistical Software 11 (8). https://doi.org/10.18637/jss.v011.i08.\n\n\nMurphy, Kevin P. 2022. Probabilistic Machine Learning: An Introduction. Adaptive Computation and Machine Learning Series. Cambridge, Massachusetts: The MIT Press."
  },
  {
    "objectID": "06_advanced-unsupervised-ml.html#footnotes",
    "href": "06_advanced-unsupervised-ml.html#footnotes",
    "title": "2  Mixture Distributions and Mixture Models",
    "section": "",
    "text": "This is solely to save computation time.↩︎"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Bishop, Christopher M. 2006. Pattern Recognition and Machine\nLearning. Information Science and Statistics. New York: Springer.\n\n\nLeisch, Friedrich. 2004. “FlexMix: A General Framework for Finite\nMixture Models and Latent Class Regression in\nR.” Journal of Statistical\nSoftware 11 (8). https://doi.org/10.18637/jss.v011.i08.\n\n\nMurphy, Kevin P. 2022. Probabilistic Machine Learning: An\nIntroduction. Adaptive Computation and Machine Learning Series.\nCambridge, Massachusetts: The MIT Press."
  }
]